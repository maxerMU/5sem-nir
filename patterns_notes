см табличку в начале higload 3
1. трех звеневая архитектура highload 2 47:46
фронтенд, бэкенд, бд
функции:
1. отдача статики
2. проверка запросов
3. буфферизация (обслуживание медленных клиентов)
4. масштабирование бекендов


2. Кеширование highload 2 52:00

сохранение результатов вычислений, сохранение данных в более быстрой среде

можно кешировать статику у пользователя

можно хранить
весь ответ 
ответ по блокам
данные
данные по блокам
чем больше, тем быстрее, но более трудоемко. Обычно хранят данные по блокам

идет кеширование по принципу ключ-значение-время жизни.

Проблемы:
обновление - сброс
запрос по ключу => проверка есть ли значение => если есть, то одать, иначе вычислить и отдать.

Приходит запрос, начинает вычислять, в этот момент приходит еще один, значение в кеше до сих пор не вычислено и опять начинает вычислять. Такое поведение называется race condition

решения: 
делать вычисления при сбросе, но в таком случае до обновления запросы могут получить старые данные 
можно по ключу хранить данные и флаг пересчета
если мы процесс, который ждет пересчет, то надо проверять сколько времени прошло с момента начала персчитывания, если это время больше некоторого определенного значения, то пересчитывающий процесс 

проблема холодного (пустого) кеша:
можно поставить ограничение на количество запросов и обрабатывать их поочереди, но тогда могут попоасть не самые популярные запросы
можно при запуске кеша запускать скрипт, который заполняет кеш по самым популярным запросам

когда кеш не нужен?
1. вычислять дешевле, чем кешировать
2. нет данных, которые запрашиваются часто


2.1 Линеаризация кеша highload3 00:00
Паттерн используется для правильного обновления кеша
По значению хранится список, из элементов которого состоит текущий элемент


3 Толстый клиент highload 3 +-20
SPA
Запрашивать обновления с определенного момента, чтобы получать обновления блоков.

Открываем длинное соединение с сервером, для этого нужно на стороне сервера comet-сервер.

сервер по таймауту посылает сообщение с обновлением или информацией о том, что ничего не произошло (ajax)
Используется в клиент-серверной архитектуре. Некоторые вычисления можно производить на клиенте. Бизнес логику переносить на клиент не безопасно. Можно выполнять фильтрации, сортировки, валидации данных. Обновление любых блоков. 

раз в 10 секунд клиент спрашивает у фронта про обновления. 1 фронт умирает, нагрузка скачкообразно возрастает на остальных фронтах и они тоже умирают. Проблема в скачкообразном росте нагрузки. 
Если фронт не справляется ... Клиент может увеличивать таймаут, по которому он отправляет запрос на следующий фронт, когда получил сообщение о том, что какой-то фронт умер. Еще можно как-то автоматически регулировать таймаут на фронте, раз в какое-то время клиент пробует уменьшить таймаут.



Балансировка нагрузки (деградация функциональности) highload 3 1:05:00
увеличиваем время обновление кеша 

Масштабирование 
горизонтальное:
надо выделить кеш на отдельную машину, чтобы пользователю было все равно на какой бек приходить (stateless - не храним состояние после выполения нет локального кеша и подобного)
Невозможно такое осуществить если несколько пользователей подключаются к одному серверу и передают друг другу информацию (многопользовательская игра)
кеш может стать единой точкой отказа
для горизонтальное масштабирования бекенды должны быть гомогенные

вертикальное:
увеличение производительности имеющийся ресурсов, функциональное разделение (для каждой логической сущности свой бек)

во времени:
не все запросы пользователя нужно выполнить сразу
отложенные вычисления
асинхронная обработка:
ставим задачу в очередь для отложенной обработки для сглаживание нагрузки
просыпается демон и обрабатывает очередь


сервисно-ориентированная архитектура VS монолитная архитектура
монолит работает быстрее
монолит быстрее разработки
-невозможно вести распределенную разработку
-в случае проблемы встает все

пишем данные в некую шину для межсервисной коммуникации

highload4 53:00
решение интеркоммуникаци сервисов без точек отказа
сервис А пишет задачу в внутреннюю очередь есть демон, который проверяет проверяет эту очередь и пытается ее передать сервису В, если от сервиса В приходит ответ, что задача принята, то она убирается из внутренней очереди А, иначе попытка повторяется.
В таком случае, если погибнет очередь сервиса А, то погибнет только сервис А, а не вся система

масштабирование баз данных связанно с САР теоремой.

Первый подход - репликация. Данные записываются в мастер базу и оттуда забираются слейв версиями. Решение обновления на клиенте через толстого клиента или отдельным запросом: покажи мне записи с учетом того, что я только что добавил новую (тогда запрос идет к мастер базе). 
Такое решение лишается доступности из САР теоремы
