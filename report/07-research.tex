\chapter{Классификация существующих решений}

Классификация паттернов, которые будут рассмотрены в этой главе представлена на рисунке \ref{img:patterns_classification.pdf}

\imgw{patterns_classification.pdf}{h!}{\textwidth}{Классификация паттернов проектирования высоконагруженных систем}

Все паттерны можно поделить на те, которые требуют введение в систему новых ресурсов, и те, которые улучшают производительность системы на основе уже существующих ресурсов. К первой категории относится масштабирование, которое может быть вертикальным, горизонтальным или во времени. Среди паттернов второй категории можно выделить трехзвенную архитектуру, кеширование и балансировку нагрузки.

\section{Трехзвенная архитектура}

На рисунке \ref{img:3node(1).pdf} представлена классическая реализация клиент-серверной архитектуры.

\imgw{3node(1).pdf}{h!}{\textwidth}{Классичическая реализация клиент-серверной архитектуры}

Клиент посылает запросы на сервер, он выполняет некоторые вычисления, делает запросы к базе данных и отправляет ответ клиенту.
Сервер, как правило, представляет собой тяжеловесную многопоточную программу, нацеленную на массивные вычисления.

Среди запросов, которые поступают на сервер, далеко не все требуют большого числа вычислений для получения ответа. Некоторые из них просто запрашивают статические данные, которые хранятся на диске. Нагружать мощный сервер, который должен производить вычисления, такими запросами -- нерационально, поэтому вводится дополнительное звено на пути от клиента к серверу, которое называется фронтендом. Его задачей является фильтрация и обработка такого рода запросов.

Схема трехзвенной архитектуры приведена на рисунке \ref{img:3node(2).pdf}.

\imgw{3node(2).pdf}{h!}{\textwidth}{Схема трехзвенной архитектуры}

Ключевым моментом во
фронтенде является то, какое количество ресурсов
тратится на обработку одного запроса, поэтому для
этого звена используются легковесные сервера \cite{cyberlenin1}.

Еще одной функцией фронтенда является буфферизация при обслуживании медленных клиентов, то есть фроненд не будет открывать соединение с бекендом до тех пор, пока не получит весь запрос целиком. Если этого не делать, то бекенд вместо выполнения вычислений будет ожидать получения данных от клиента.

\section{Балансировка нагрузки}\label{sec:load_balance}

Третьей функцией фронтенда является распределение запросов между бекендами, когда их больше одного. Схема такой архитектуры представлена на рисунке \ref{img:3node(3).pdf}.

\imgw{3node(3).pdf}{h!}{\textwidth}{Балансировка нагрузки через фронтенд}

Стратегия балансировки нагрузки преследует следующие цели \cite{cyberlenin2}:
\begin{itemize}
	\item оптимальная общая производительность системы, то есть не должно возникать таких ситуация, при которых часть системы работает на пределе своих мощностей, а другая не работает вовсе;
	\item справедливость обслуживания -- все задания должны обслуживаться с одинаковым уровнем привилегий вне зависимости от их происхождения;
	\item устойчивость к отказам -- поддержание производительности системы при наличии частичных отказов.
\end{itemize}

Существуют различные методы балансировки нагрузки, которые помогают достичь эти цели, их классификация представлена на рисунке \ref{img:3node(4).pdf}.

\imgw{3node(4).pdf}{h!}{\textwidth}{Классификация методов балансировка нагрузки}


\subsection{Статические методы}

Во всех статических методах балансировки вся информация о процессах собирается до их обработки. После назначения процессу обработчика он уже никогда не может перейти к другому \cite{cyberlenin2}.

Статические методы можно поделить на детерминированные и вероятностные. Первые назначают задачи по какому-то фиксированному критерию. К примеру, можно высчитывать хеш функцию от IP адреса клиента. Вероятностные методы распределяют задачи по обработчикам с некоторой вероятностью. Примером такого метода является weighted round robin. При таком подходе каждый сервер имеет заранее определенный вес, который, к примеру, может зависеть от мощностей сервера. Балансировщик нагрузки обходит все серверы по кругу и выдает им задачи в зависимости от их веса.

Главным недостатком статических методов является то, что они при принятии решений никак не учитывают колебания нагрузки на систему \cite{cyberlenin2}.

\subsection{Динамические методы}

\subsubsection{Стратегия заявок}

Загруженный процессор посылает запрос на получение заявок на обработку его задач от других процессоров. Главный процессор получает информацию о заявках и статусе выполнения каждого сервера системы и выбирает, кому передать группу задач, с которой не справляется загруженный узел. 

Основной проблемой такого подхода является ситуация, при которой процессор, который принял на себя группу задач, сам перестал справляться с нагрузкой \cite{cyberlenin2}. Для решения этой проблемы некоторые вариации метода заявок позволяют процессору, отправившему заявку на получение группы задач отклонять некоторые задачи и посылать их обратно главному. Для этого должна быть реализована возможность передачи сообщений от процессоров, выполняющих задачи, к основному.

\subsubsection{Стратегия отбора}

В стратегии заявок часть процессов переходит с одного сервера на другой и возвращается обратно из-за непредсказуемого роста нагрузки на процессор, отправивший заявку. Для решения этой проблемы в стратегии отбора процессы переходят не группами, а по одному.

В стратегии отбора миграцию инициируют малонагруженные процессоры. Каждый из процессоров определяет одно из трех состояний своей загруженности: HLOAD - высоконагруженный, NLOAD - обычная нагрузка или LLOAD - слабая нагрузка \cite{cyberlenin2}. Каждый из серверов хранит таблицу нагрузки других, и, когда его состояние изменяется, он посылает всем остальным оповещение с новым состоянием.

Если сервер переходит в состояние LLOAD, то он выбирает из таблицы загруженный сервер и инициирует миграцию процесса.

\subsubsection{Стратегия порога}

При таком подходе для каждого сервера выставляется пороговое значение, которое сравнивается с длинной очереди на выполнение при поступлении новой задачи. Длина этой очереди считается как сумма количества задача, которые в данный момент выполняются и тех, что находятся в ожидании получения ресурсов.

Если при поступлении задачи длина очереди равна некотором заранее установленному значению, то случайным образом выбирается другой сервер, которому она будет отправлена. Если у выбранного сервера также достигнуто пороговое значение, то он аналогичным образом передаст задачу другому. Процесс будет продолжаться до тех пор, пока не будет найден подходящий сервер.

Главным преимуществом такого подхода является то, что серверам никак не нужно между собой коммуницировать, что ускоряет процесс обработки \cite{cyberlenin2}.

\subsubsection{Жадная стратегия}

При таком подходе состояние каждого сервера описывается некоторой функцией $f(n)$, где $n$ -- число задач на текущем сервере. Если на момент поступления новой задачи число $n$ больше нуля, то начинаются поиски нового сервера, состояние $f(n)$ которого меньше или равно состоянию текущего. Если такой был найден, то задача передается ему. 

Исследования \cite{greedyalg} показывают, что жадная стратегия превосходит стратегию порога из-за того, что при жадном подходе происходит попытка передать все задачи, которые приходят на занятый сервер, в то время как при стратегии порога задачи передаются только при достижении какого-то критического значения длины очереди.

\section{Кеширование}

Кеширование - это техника, направленная на повышение производительности системы, за счет временного копирования часто используемых данных в быстрое хранилище, расположенное рядом с приложением \cite{caching}.

Существует несколько разных подходов к организации кеширования:
\begin{itemize}
	\item кеш хранится локально на каждой машине, где запущено приложение;
	\item кеш хранится отдельно на удаленной машине, он один общий для всех машин.
\end{itemize}

Одной из основных проблем глобального кеша является его обновление. Общая схема кеширования представлена на рисунке \ref{img:caching1.pdf}.

\imgs{caching1.pdf}{H}{0.7}{Общая схема организации кеширования}

Проблемы в такой системе возникают, когда сразу несколько процессов запрашивают данные, которых нет в кеше, и начинают их вычислять параллельно. В таких случаях начинает расти нагрузка на базу данных, так как к ней приходят запросы на одни и те же данные, что повышает нагрузку на систему целиком.

Для предотвращения этой проблемы процесс, который начал вычисления, должен выставить некий флаг, сообщающий другим процессам, что данные вычисляются и через какое-то время появятся в кеше. 

Также требуется ввести ограничение на время вычисления. Если процесс, установивший флаг, не вычислил данные в кеше за отведенное время, значит в что-то сработало не в штатном режиме, к примеру, процесс мог аварийно завершиться. В таком случае первый процесс, который обнаружит эту задержку должен взять вычисления на себя и обновить соответствующий флаг.

Схема такой обработки кеша приведена на рисунке \ref{img:caching2.pdf}.

\imgs{caching2.pdf}{h!}{0.7}{Кеширование с флагом о вычислении}

Еще одной проблемой кеширования данных является зависимость разных блоков от одной и той же единицы информации (кешировать можно не только отдельные данные, но и блоки целиком). Возникает вопрос, как при обновлении единицы информации обновить все блоки, которые от нее зависят?

Для решения этой проблемы существуют два различных способа: сброс кешей при наступлении определенного события и тегирование кешей.

При первом подходе составляется граф, который определяет какие блоки зависят от каждой единицы данных. При обновлении информации  каждого куска сбрасываются все блоки, которые от него зависят.

Второй вариант основан на создании обратного графа, который определяет от каких кусков данных зависит каждый блок. Каждая единица информации подвергается тегированию, то есть помимо полезных данных она должна хранить текущую версию или время создания. В таком случаем при запросе каждого блока информации идет сравнение версий или времени обновления каждого из его кусков с их оригинальными версиями, если оно меньше, то этот кусок обновляется в блоке.

Также важно заполнять кеш, к которому идет наибольшее число обращений, перед началом стартом работы сервера. Нужно это для предотвращения проблемы запуска с "непрогретмым" кешом, когда при перезапуске сервера все запросы начинают высчитывать данные в кеше.

\section{Масштабирование}

\subsection{Вертикальное масштабирование}

Принцип вертикального масштабирования заключается в замене имеющихся ресурсов на более мощные. По проведенным исследованиям \cite{henderson} стоимость не масштабируется линейно относительно введенных ресурсов. Также такой подход сталкивается с ограничением мощностей вычислительных машин.

\subsection{Горизонтальное масштабирование}

Суть горизонтального масштабирования заключается не в замене имеющихся машин на более мощные, а в добавлении новых и распределении нагрузки между ними. Подходы к балансировке нагрузки были рассмотрены в разделе \ref{sec:load_balance}.

При горизонтальном масштабировании не всегда будет наблюдаться линейный рост производительности от количества добавленных в систему ресурсов, так как узлы системы должны обмениваться между собой сообщениями для получения общего результата работы \cite{henderson}. Такое поведение подчиняется закону Амдала, согласно которому ускорение выполнения программы за счёт распараллеливания её инструкций на множестве вычислителей ограничено временем, необходимым для выполнения её последовательных инструкций.

Горизонтальное масштабирование возможно только для stateless систем - таких, которые не изменяют и не сохраняют свое состояние после выполнения запроса \cite{burns}.

Также возможно запускать на разных серверах не копии приложения, а его отдельные функциональные части.

Горизонтальное масштабирование может применяться к любому из звеньев трехзвенной структуры.

\subsection{Масштабирование во времени}

Далеко не все запросы надо выполнять сразу после их поступления. При поступлении некоторых рода задач можно ставить их в некую очередь, которая будет постепенно просматриваться обработчиком. При таком подходе клиент получает ответ, что его запрос обрабатывается, и соединение с ним закрывается.

Также очереди можно использовать для межсервисной коммуникации. Некий сервис А ставит задачу сервису Б и добавляет ее в свою очередь задач. Специальная программа разбирает эту очередь и пытается отправить сообщение сервису Б и ждет от него ответа. Задача убирается из очереди только тогда, когда от сервиса Б пришел ответ, что сообщение обработано, иначе попытка повторяется.

\section{Вывод}

Каждый из проанализированных используется в зависимости от поставленных целей и входных данных.

Трехзвенную архитектуру стоит применять, когда существует возможность обслуживания медленных клиентов, есть запросы, которые не требуют вычислений, к примеру, отдача статики и когда предполагается масштабирование бекендов.

Кеширование повышает производительность системы, когда есть данные, которые не часто изменяются, но может наоборот замедлить работу системы, когда данные изменяются часто. Также если вычисления стоят дешевле, чем хранение информации, то кеширование нецелесообразно.

Балансировка нагрузки применяется в случаях создания распределенных систем. Ее алгоритмы повышают производительность системы, но не являются тривиальными в реализации.